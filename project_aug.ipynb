{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "# 打開 train.txt 以及 train_aug.txt 作為讀取和寫入文件\n",
    "with open('train.txt', 'r') as source_file, open('train_aug.txt', 'w') as target_file:\n",
    "    # 讀取 train.txt 的每一行並將其寫入 train_aug.txt\n",
    "    for line in source_file:\n",
    "        data=line.split()\n",
    "        data[0]=data[0][:-4]+'_tile.jpg'\n",
    "        data[2]=str(1-float(data[2]))\n",
    "        target_file.write(' '.join(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 打開 train.txt 以及 train_aug.txt 作為讀取和附加文件\n",
    "with open('train.txt', 'r') as source_file, open('train_aug.txt', 'a') as target_file:\n",
    "    # 將 train.txt 的每一行內容附加到 train_aug.txt\n",
    "    for line in source_file:\n",
    "        target_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# 检查并创建 merged_image_aug 文件夹\n",
    "folder_name = 'merged_image_aug'\n",
    "if not os.path.exists(folder_name):\n",
    "    os.makedirs(folder_name)\n",
    "\n",
    "# 遍历 merged_image 文件夹内的所有图片文件\n",
    "merged_image_folder = 'merged_image'\n",
    "for filename in os.listdir(merged_image_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # 假设图片格式为 jpg 或 png\n",
    "        # 读取图片\n",
    "        image_path = os.path.join(merged_image_folder, filename)\n",
    "        img = Image.open(image_path)\n",
    "\n",
    "        # 上下翻转图片\n",
    "        flipped_img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "\n",
    "        # 创建保存翻转后图片的路径\n",
    "        save_path = os.path.join(folder_name, f\"flipped_{filename}\")\n",
    "\n",
    "        # 保存翻转后的图片到 merged_image_aug 文件夹\n",
    "        flipped_img.save(save_path)\n",
    "\n",
    "        # 关闭当前图片\n",
    "        img.close()\n",
    "        flipped_img.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原始图片所在的文件夹路径\n",
    "source_folder = 'merged_image'\n",
    "\n",
    "# 目标图片要复制到的文件夹路径\n",
    "destination_folder = 'merged_image_aug'\n",
    "\n",
    "# 遍历原始图片文件夹，将其中的图片复制到目标文件夹\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):  # 假设图片格式为 jpg 或 png\n",
    "        # 构建源文件路径和目标文件路径\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        destination_path = os.path.join(destination_folder, filename)\n",
    "\n",
    "        # 复制图片文件\n",
    "        shutil.copyfile(source_path, destination_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "train_file = 'train_aug.txt'\n",
    "test_file = 'test_aug.txt'\n",
    "lines_to_remove = 100\n",
    "\n",
    "# 開啟 train.txt 並讀取所有行\n",
    "with open(train_file, 'r') as train:\n",
    "    lines = train.readlines()\n",
    "\n",
    "# 隨機挑選要移除的行數\n",
    "random_lines = random.sample(lines, lines_to_remove)\n",
    "\n",
    "# 從原始的 train.txt 中移除選擇的行\n",
    "updated_lines = [line for line in lines if line not in random_lines]\n",
    "\n",
    "# 將移除的行寫入 test.txt\n",
    "with open(test_file, 'w') as test:\n",
    "    test.writelines(random_lines)\n",
    "\n",
    "# 更新 train.txt，移除已選擇的行\n",
    "with open(train_file, 'w') as train:\n",
    "    train.writelines(updated_lines)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        # Currently, memory growth needs to be the same across GPUs\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        # Select GPU number 1\n",
    "        tf.config.experimental.set_visible_devices(gpus[0], 'GPU')\n",
    "        logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "        print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "    except RuntimeError as e:\n",
    "        # Memory growth must be set before GPUs have been initialized\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# common params\n",
    "IMAGE_SIZE = 400\n",
    "BATCH_SIZE = 8\n",
    "NUM_CLASSES = 2\n",
    "MAX_OBJECTS_PER_IMAGE = 1\n",
    "\n",
    "# dataset params\n",
    "DATA_PATH = './train_aug.txt'\n",
    "IMAGE_DIR = './merged_image_aug'\n",
    "\n",
    "# model params\n",
    "CELL_SIZE = 7\n",
    "BOXES_PER_CELL = 2\n",
    "OBJECT_SCALE = 1\n",
    "NOOBJECT_SCALE = 0.5\n",
    "CLASS_SCALE = 1\n",
    "COORD_SCALE = 5\n",
    "\n",
    "# training params\n",
    "LEARNING_RATE = 1e-4\n",
    "EPOCHS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetGenerator:\n",
    "    \"\"\"\n",
    "    creates an input pipeline.\n",
    "    - Reshapes images into 448 x 448\n",
    "    - converts [0 1] to [-1 1]\n",
    "    - shuffles the input\n",
    "    - builds batches\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.image_names = []\n",
    "        self.record_list = []\n",
    "        self.object_num_list = []\n",
    "        # filling the record_list\n",
    "        input_file = open(DATA_PATH, 'r')\n",
    "\n",
    "        for line in input_file:\n",
    "            line = line.strip()\n",
    "            ss = line.split(' ')\n",
    "            self.image_names.append(os.path.join(IMAGE_DIR,ss[0]))\n",
    "\n",
    "            self.record_list.append([float(num) for num in ss[1:]])\n",
    "\n",
    "            self.object_num_list.append(min(len(self.record_list[-1])//5, \n",
    "                                            MAX_OBJECTS_PER_IMAGE))\n",
    "            if len(self.record_list[-1]) < MAX_OBJECTS_PER_IMAGE*5:\n",
    "                # if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\n",
    "                self.record_list[-1] = self.record_list[-1] +\\\n",
    "                [0., 0., 0., 0., 0.]*\\\n",
    "                (MAX_OBJECTS_PER_IMAGE-len(self.record_list[-1])//5)\n",
    "                \n",
    "            elif len(self.record_list[-1]) > MAX_OBJECTS_PER_IMAGE*5:\n",
    "               # if there are objects more than MAX_OBJECTS_PER_IMAGE, crop the list\n",
    "                self.record_list[-1] = self.record_list[-1][:MAX_OBJECTS_PER_IMAGE*5]\n",
    "\n",
    "    def _data_preprocess(self, image_name, raw_labels, object_num):\n",
    "        image_file = tf.io.read_file(image_name)\n",
    "        image = tf.io.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "        h = tf.shape(image)[0]\n",
    "        w = tf.shape(image)[1]\n",
    "\n",
    "        width_ratio  = IMAGE_SIZE * 1.0 / tf.cast(w, tf.float32) \n",
    "        height_ratio = IMAGE_SIZE * 1.0 / tf.cast(h, tf.float32) \n",
    "\n",
    "        image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "        image = (image/255) * 2 - 1\n",
    "\n",
    "        raw_labels = tf.cast(tf.reshape(raw_labels, [-1, 5]), tf.float32)\n",
    "\n",
    "        xcenter = raw_labels[:, 0]\n",
    "        ycenter = raw_labels[:, 1]\n",
    "        box_w = raw_labels[:, 2]\n",
    "        box_h = raw_labels[:, 3]\n",
    "        class_num = raw_labels[:, 4]\n",
    "\n",
    "        \n",
    "\n",
    "        labels = tf.stack([xcenter, ycenter, box_w, box_h, class_num], axis=1)\n",
    "\n",
    "        return image, labels, tf.cast(object_num, tf.int32)\n",
    "\n",
    "    def generate(self):\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((self.image_names, \n",
    "                                                      np.array(self.record_list), \n",
    "                                                      np.array(self.object_num_list)))\n",
    "        dataset = dataset.shuffle(100000)\n",
    "        dataset = dataset.map(self._data_preprocess, \n",
    "                              num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "        dataset = dataset.batch(BATCH_SIZE)\n",
    "        dataset = dataset.prefetch(buffer_size=200)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def conv_leaky_relu(inputs, filters, size, stride):\n",
    "    x = layers.Conv2D(filters, size, stride, padding=\"same\",\n",
    "                      kernel_initializer=tf.keras.initializers.TruncatedNormal())(inputs)\n",
    "    x = layers.LeakyReLU(0.1)(x)\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "img_inputs = keras.Input(shape=(IMAGE_SIZE, IMAGE_SIZE, 3))\n",
    "x = conv_leaky_relu(img_inputs, 64, 7, 2)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 192, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 128, 1, 1)\n",
    "x = conv_leaky_relu(x, 256, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 256, 1, 1)\n",
    "x = conv_leaky_relu(x, 512, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.MaxPool2D()(x)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 512, 1, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 2)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = conv_leaky_relu(x, 1024, 3, 1)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(4096, \n",
    "                 kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "x = layers.LeakyReLU(0.1)(x)\n",
    "outputs = layers.Dense(588, \n",
    "                       kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.01))(x)\n",
    "\n",
    "YOLO = keras.Model(inputs=img_inputs, outputs=outputs, name=\"YOLO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"YOLO\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 400, 400, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 200, 200, 64)      9472      \n",
      "                                                                 \n",
      " leaky_re_lu (LeakyReLU)     (None, 200, 200, 64)      0         \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 100, 100, 64)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 100, 100, 192)     110784    \n",
      "                                                                 \n",
      " leaky_re_lu_1 (LeakyReLU)   (None, 100, 100, 192)     0         \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 50, 50, 192)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 50, 50, 128)       24704     \n",
      "                                                                 \n",
      " leaky_re_lu_2 (LeakyReLU)   (None, 50, 50, 128)       0         \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 50, 50, 256)       295168    \n",
      "                                                                 \n",
      " leaky_re_lu_3 (LeakyReLU)   (None, 50, 50, 256)       0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 50, 50, 256)       65792     \n",
      "                                                                 \n",
      " leaky_re_lu_4 (LeakyReLU)   (None, 50, 50, 256)       0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 50, 50, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_5 (LeakyReLU)   (None, 50, 50, 512)       0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 25, 25, 512)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 25, 25, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_6 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_7 (LeakyReLU)   (None, 25, 25, 512)       0         \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 25, 25, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_8 (LeakyReLU)   (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_9 (LeakyReLU)   (None, 25, 25, 512)       0         \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 25, 25, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_10 (LeakyReLU)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_11 (LeakyReLU)  (None, 25, 25, 512)       0         \n",
      "                                                                 \n",
      " conv2d_12 (Conv2D)          (None, 25, 25, 256)       131328    \n",
      "                                                                 \n",
      " leaky_re_lu_12 (LeakyReLU)  (None, 25, 25, 256)       0         \n",
      "                                                                 \n",
      " conv2d_13 (Conv2D)          (None, 25, 25, 512)       1180160   \n",
      "                                                                 \n",
      " leaky_re_lu_13 (LeakyReLU)  (None, 25, 25, 512)       0         \n",
      "                                                                 \n",
      " conv2d_14 (Conv2D)          (None, 25, 25, 512)       262656    \n",
      "                                                                 \n",
      " leaky_re_lu_14 (LeakyReLU)  (None, 25, 25, 512)       0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 25, 25, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_15 (LeakyReLU)  (None, 25, 25, 1024)      0         \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 12, 12, 1024)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 12, 12, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_16 (LeakyReLU)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 12, 12, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_17 (LeakyReLU)  (None, 12, 12, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 12, 12, 512)       524800    \n",
      "                                                                 \n",
      " leaky_re_lu_18 (LeakyReLU)  (None, 12, 12, 512)       0         \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 12, 12, 1024)      4719616   \n",
      "                                                                 \n",
      " leaky_re_lu_19 (LeakyReLU)  (None, 12, 12, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 12, 12, 1024)      9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_20 (LeakyReLU)  (None, 12, 12, 1024)      0         \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 6, 6, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_21 (LeakyReLU)  (None, 6, 6, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 6, 6, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_22 (LeakyReLU)  (None, 6, 6, 1024)        0         \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 6, 6, 1024)        9438208   \n",
      "                                                                 \n",
      " leaky_re_lu_23 (LeakyReLU)  (None, 6, 6, 1024)        0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 36864)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              150999040 \n",
      "                                                                 \n",
      " leaky_re_lu_24 (LeakyReLU)  (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 588)               2409036   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 213564044 (814.68 MB)\n",
      "Trainable params: 213564044 (814.68 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "YOLO.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base boxes (for loss calculation)\n",
    "base_boxes = np.zeros([CELL_SIZE, CELL_SIZE, 4])\n",
    "\n",
    "# initializtion for each cell\n",
    "for y in range(CELL_SIZE):\n",
    "    for x in range(CELL_SIZE):\n",
    "        base_boxes[y, x, :] = [IMAGE_SIZE / CELL_SIZE * x, \n",
    "                               IMAGE_SIZE / CELL_SIZE * y, 0, 0]\n",
    "\n",
    "base_boxes = np.resize(base_boxes, [CELL_SIZE, CELL_SIZE, 1, 4])\n",
    "base_boxes = np.tile(base_boxes, [1, 1, BOXES_PER_CELL, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iou(boxes1, boxes2):\n",
    "    \"\"\"calculate ious\n",
    "    Args:\n",
    "      boxes1: 4-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 4]  ====> (x_center, y_center, w, h)\n",
    "      boxes2: 1-D tensor [4] ===> (x_center, y_center, w, h)\n",
    "\n",
    "    Return:\n",
    "      iou: 3-D tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "      ====> iou score for each cell\n",
    "    \"\"\"\n",
    "\n",
    "    #boxes1 : [4(xmin, ymin, xmax, ymax), cell_size, cell_size, boxes_per_cell]\n",
    "    boxes1 = tf.stack([boxes1[:, :, :, 0] - boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] - boxes1[:, :, :, 3] / 2,\n",
    "                      boxes1[:, :, :, 0] + boxes1[:, :, :, 2] / 2, boxes1[:, :, :, 1] + boxes1[:, :, :, 3] / 2])\n",
    "\n",
    "    #boxes1 : [cell_size, cell_size, boxes_per_cell, 4(xmin, ymin, xmax, ymax)]\n",
    "    boxes1 = tf.transpose(boxes1, [1, 2, 3, 0])\n",
    "\n",
    "    boxes2 =  tf.stack([boxes2[0] - boxes2[2] / 2, boxes2[1] - boxes2[3] / 2,\n",
    "                      boxes2[0] + boxes2[2] / 2, boxes2[1] + boxes2[3] / 2])\n",
    "\n",
    "    #calculate the left up point of boxes' overlap area\n",
    "    lu = tf.maximum(boxes1[:, :, :, 0:2], boxes2[0:2])\n",
    "    #calculate the right down point of boxes overlap area\n",
    "    rd = tf.minimum(boxes1[:, :, :, 2:], boxes2[2:])\n",
    "\n",
    "    #intersection\n",
    "    intersection = rd - lu \n",
    "\n",
    "    #the size of the intersection area\n",
    "    inter_square = intersection[:, :, :, 0] * intersection[:, :, :, 1]\n",
    "\n",
    "    mask = tf.cast(intersection[:, :, :, 0] > 0, tf.float32) * tf.cast(intersection[:, :, :, 1] > 0, tf.float32)\n",
    "\n",
    "    #if intersection is negative, then the boxes don't overlap\n",
    "    inter_square = mask * inter_square\n",
    "\n",
    "    #calculate the boxs1 square and boxs2 square\n",
    "    square1 = (boxes1[:, :, :, 2] - boxes1[:, :, :, 0]) * (boxes1[:, :, :, 3] - boxes1[:, :, :, 1])\n",
    "    square2 = (boxes2[2] - boxes2[0]) * (boxes2[3] - boxes2[1])\n",
    "\n",
    "    return inter_square/(square1 + square2 - inter_square + 1e-6)\n",
    "\n",
    "def losses_calculation(predict, label):\n",
    "    \"\"\"\n",
    "    calculate loss\n",
    "    Args:\n",
    "      predict: 3-D tensor [cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "      label : [1, 5]  (x_center, y_center, w, h, class)\n",
    "    \"\"\"\n",
    "    label = tf.reshape(label, [-1])\n",
    "\n",
    "    #Step A. calculate objects tensor [CELL_SIZE, CELL_SIZE]\n",
    "    #turn pixel position into cell position (corner)\n",
    "    min_x = (label[0] - label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_x = (label[0] + label[2] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_y = (label[1] - label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "    max_y = (label[1] + label[3] / 2) / (IMAGE_SIZE / CELL_SIZE)\n",
    "\n",
    "    min_x = tf.floor(min_x)\n",
    "    min_y = tf.floor(min_y)\n",
    "\n",
    "    max_x = tf.minimum(tf.math.ceil(max_x), CELL_SIZE)\n",
    "    max_y = tf.minimum(tf.math.ceil(max_y), CELL_SIZE)\n",
    "    \n",
    "    #calculate mask of object with cells\n",
    "    onset = tf.cast(tf.stack([max_y - min_y, max_x - min_x]), dtype=tf.int32)\n",
    "    object_mask = tf.ones(onset, tf.float32)\n",
    "\n",
    "    offset = tf.cast(tf.stack([min_y, CELL_SIZE - max_y, min_x, CELL_SIZE - max_x]), tf.int32)\n",
    "    offset = tf.reshape(offset, (2, 2))\n",
    "    object_mask = tf.pad(object_mask, offset, \"CONSTANT\")\n",
    "\n",
    "    #Step B. calculate the coordination of object center and the corresponding mask\n",
    "    #turn pixel position into cell position (center)\n",
    "    center_x = label[0] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_x = tf.floor(center_x)\n",
    "\n",
    "    center_y = label[1] / (IMAGE_SIZE / CELL_SIZE)\n",
    "    center_y = tf.floor(center_y)\n",
    "\n",
    "    response = tf.ones([1, 1], tf.float32)\n",
    "\n",
    "    #calculate the coordination of object center with cells\n",
    "    objects_center_coord = tf.cast(tf.stack([center_y, CELL_SIZE - center_y - 1, \n",
    "                             center_x, CELL_SIZE - center_x - 1]), \n",
    "                             tf.int32)\n",
    "    objects_center_coord = tf.reshape(objects_center_coord, (2, 2))\n",
    "\n",
    "    #make mask\n",
    "    response = tf.pad(response, objects_center_coord, \"CONSTANT\")\n",
    "\n",
    "    #Step C. calculate iou_predict_truth [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    predict_boxes = predict[:, :, NUM_CLASSES + BOXES_PER_CELL:]\n",
    "\n",
    "    predict_boxes = tf.reshape(predict_boxes, [CELL_SIZE, \n",
    "                                               CELL_SIZE, \n",
    "                                               BOXES_PER_CELL, 4])\n",
    "    #cell position to pixel position\n",
    "    predict_boxes = predict_boxes * [IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE / CELL_SIZE, \n",
    "                                     IMAGE_SIZE, IMAGE_SIZE]\n",
    "\n",
    "    #if there's no predict_box in that cell, then the base_boxes will be calcuated with label and got iou equals 0\n",
    "    predict_boxes = base_boxes + predict_boxes\n",
    "\n",
    "    iou_predict_truth = iou(predict_boxes, label[0:4])\n",
    "\n",
    "    #calculate C tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    C = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    #calculate I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    I = iou_predict_truth * tf.reshape(response, [CELL_SIZE, CELL_SIZE, 1])\n",
    "\n",
    "    max_I = tf.reduce_max(I, 2, keepdims=True)\n",
    "\n",
    "    #replace large iou scores with response (object center) value\n",
    "    I = tf.cast((I >= max_I), tf.float32) * tf.reshape(response, (CELL_SIZE, CELL_SIZE, 1))\n",
    "\n",
    "    #calculate no_I tensor [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    no_I = tf.ones_like(I, dtype=tf.float32) - I\n",
    "\n",
    "    p_C = predict[:, :, NUM_CLASSES:NUM_CLASSES + BOXES_PER_CELL]\n",
    "\n",
    "    #calculate truth x, y, sqrt_w, sqrt_h 0-D\n",
    "    x = label[0]\n",
    "    y = label[1]\n",
    "\n",
    "    sqrt_w = tf.sqrt(tf.abs(label[2]))\n",
    "    sqrt_h = tf.sqrt(tf.abs(label[3]))\n",
    "\n",
    "    #calculate predict p_x, p_y, p_sqrt_w, p_sqrt_h 3-D [CELL_SIZE, CELL_SIZE, BOXES_PER_CELL]\n",
    "    p_x = predict_boxes[:, :, :, 0]\n",
    "    p_y = predict_boxes[:, :, :, 1]\n",
    "\n",
    "    p_sqrt_w = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 2])))\n",
    "    p_sqrt_h = tf.sqrt(tf.minimum(IMAGE_SIZE * 1.0, tf.maximum(0.0, predict_boxes[:, :, :, 3])))\n",
    "\n",
    "    #calculate ground truth p 1-D tensor [NUM_CLASSES]\n",
    "    P = tf.one_hot(tf.cast(label[4], tf.int32), NUM_CLASSES, dtype=tf.float32)\n",
    "\n",
    "    #calculate predicted p_P 3-D tensor [CELL_SIZE, CELL_SIZE, NUM_CLASSES]\n",
    "    p_P = predict[:, :, 0:NUM_CLASSES]\n",
    "\n",
    "    #class_loss\n",
    "    class_loss = tf.nn.l2_loss(tf.reshape(object_mask, (CELL_SIZE, CELL_SIZE, 1)) * (p_P - P)) * CLASS_SCALE\n",
    "\n",
    "    #object_loss\n",
    "    object_loss = tf.nn.l2_loss(I * (p_C - C)) * OBJECT_SCALE\n",
    "\n",
    "    #noobject_loss\n",
    "    noobject_loss = tf.nn.l2_loss(no_I * (p_C)) * NOOBJECT_SCALE\n",
    "\n",
    "    #coord_loss\n",
    "    coord_loss = (tf.nn.l2_loss(I * (p_x - x)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_y - y)/(IMAGE_SIZE/CELL_SIZE)) +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_w - sqrt_w))/IMAGE_SIZE +\n",
    "                  tf.nn.l2_loss(I * (p_sqrt_h - sqrt_h))/IMAGE_SIZE) * COORD_SCALE\n",
    "\n",
    "    return class_loss + object_loss + noobject_loss + coord_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yolo_loss(predicts, labels, objects_num):\n",
    "    \"\"\"\n",
    "    Add Loss to all the trainable variables\n",
    "    Args:\n",
    "        predicts: 4-D tensor [batch_size, cell_size, cell_size, num_classes + 5 * boxes_per_cell]\n",
    "        ===> (num_classes, boxes_per_cell, 4 * boxes_per_cell)\n",
    "        labels  : 3-D tensor of [batch_size, max_objects, 5]\n",
    "        objects_num: 1-D tensor [batch_size]\n",
    "    \"\"\"\n",
    "\n",
    "    loss = 0.\n",
    "    \n",
    "    #you can parallel the code with tf.map_fn or tf.vectorized_map (big performance gain!)\n",
    "    for i in tf.range(min(BATCH_SIZE,predicts.shape[0])):\n",
    "        predict = predicts[i, :, :, :]\n",
    "        label = labels[i, :, :]\n",
    "        object_num = objects_num[i]\n",
    "\n",
    "        for j in tf.range(object_num):\n",
    "            results = losses_calculation(predict, label[j:j+1, :])\n",
    "            loss = loss + results\n",
    "\n",
    "    return loss/min(BATCH_SIZE,predicts.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '01_2_826_0_1_3680043_2_966_20151014152623_416_753_tile.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDatasetGenerator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerate()\n\u001b[0;32m      2\u001b[0m dataset\n",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m, in \u001b[0;36mDatasetGenerator.__init__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     19\u001b[0m ss \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_names\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_DIR,ss[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28mfloat\u001b[39m(num) \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m ss[\u001b[38;5;241m1\u001b[39m:]])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_num_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     25\u001b[0m                                 MAX_OBJECTS_PER_IMAGE))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m MAX_OBJECTS_PER_IMAGE\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[8], line 22\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     19\u001b[0m ss \u001b[38;5;241m=\u001b[39m line\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mimage_names\u001b[38;5;241m.\u001b[39mappend(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(IMAGE_DIR,ss[\u001b[38;5;241m0\u001b[39m]))\n\u001b[1;32m---> 22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list\u001b[38;5;241m.\u001b[39mappend([\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m num \u001b[38;5;129;01min\u001b[39;00m ss[\u001b[38;5;241m1\u001b[39m:]])\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobject_num_list\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m5\u001b[39m, \n\u001b[0;32m     25\u001b[0m                                 MAX_OBJECTS_PER_IMAGE))\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrecord_list[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m<\u001b[39m MAX_OBJECTS_PER_IMAGE\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5\u001b[39m:\n\u001b[0;32m     27\u001b[0m     \u001b[38;5;66;03m# if there are objects less than MAX_OBJECTS_PER_IMAGE, pad the list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: '01_2_826_0_1_3680043_2_966_20151014152623_416_753_tile.jpg'"
     ]
    }
   ],
   "source": [
    "dataset = DatasetGenerator().generate()\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(LEARNING_RATE)\n",
    "train_loss_metric = tf.keras.metrics.Mean(name='loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(image, labels, objects_num):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = YOLO(image)\n",
    "        class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "        conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "        class_probs = tf.reshape(outputs[:, 0:class_end], (-1, 7, 7, 2))  #modify 20->2\n",
    "        confs = tf.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "        boxes = tf.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "        predicts = tf.concat([class_probs, confs, boxes], 3)\n",
    "\n",
    "        loss = yolo_loss(predicts, labels, objects_num)\n",
    "        train_loss_metric(loss)\n",
    "\n",
    "    grads = tape.gradient(loss, YOLO.trainable_weights)\n",
    "    optimizer.apply_gradients(zip(grads, YOLO.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-12-18 15:56:20.816326, start training.\n",
      "2023-12-18 15:57:21.360825, Epoch 1: loss 2873.84\n",
      "2023-12-18 15:58:15.811325, Epoch 2: loss 1.57\n",
      "2023-12-18 15:59:10.696326, Epoch 3: loss 1.08\n",
      "2023-12-18 16:00:05.597327, Epoch 4: loss 0.86\n",
      "2023-12-18 16:01:00.749327, Epoch 5: loss 0.74\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "print(\"{}, start training.\".format(datetime.now()))\n",
    "for i in range(EPOCHS):\n",
    "    train_loss_metric.reset_states()\n",
    "\n",
    "    for idx, (image, labels, objects_num) in enumerate(dataset):\n",
    "        train_step(image, labels, objects_num)\n",
    "\n",
    "    print(\"{}, Epoch {}: loss {:.2f}\".format(datetime.now(), i+1, train_loss_metric.result()))\n",
    "\n",
    "    #save_path = manager.save()\n",
    "    #print(\"Saved checkpoint for epoch {}: {}\".format(int(ckpt.epoch), save_path)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_outputs(outputs):\n",
    "    \"\"\"\n",
    "    Process YOLO outputs into bounding boxes\n",
    "    \"\"\"\n",
    "\n",
    "    class_end = CELL_SIZE * CELL_SIZE * NUM_CLASSES\n",
    "    conf_end = class_end + CELL_SIZE * CELL_SIZE * BOXES_PER_CELL\n",
    "    class_probs = np.reshape(outputs[:, 0:class_end], (-1, 7, 7, 2))   #modify 20->2\n",
    "    confs = np.reshape(outputs[:, class_end:conf_end], (-1, 7, 7, 2))\n",
    "    boxes = np.reshape(outputs[:, conf_end:], (-1, 7, 7, 2*4))\n",
    "    predicts = np.concatenate([class_probs, confs, boxes], 3)\n",
    "\n",
    "    p_classes = predicts[0, :, :, 0:2]\n",
    "    C = predicts[0, :, :, 2:4]\n",
    "    coordinate = predicts[0, :, :, 4:]\n",
    "\n",
    "    p_classes = np.reshape(p_classes, (CELL_SIZE, CELL_SIZE, 1, 2))\n",
    "    C = np.reshape(C, (CELL_SIZE, CELL_SIZE, BOXES_PER_CELL, 1))\n",
    "\n",
    "    P = C * p_classes\n",
    "\n",
    "    #choose the most confidence one\n",
    "    max_conf = np.max(P)\n",
    "    index = np.argmax(P)\n",
    "\n",
    "    index = np.unravel_index(index, P.shape)\n",
    "\n",
    "    class_num = index[3]\n",
    "\n",
    "    coordinate = np.reshape(coordinate, \n",
    "                            (CELL_SIZE, \n",
    "                             CELL_SIZE,\n",
    "                             BOXES_PER_CELL, \n",
    "                             4))\n",
    "\n",
    "    max_coordinate = coordinate[index[0], index[1], index[2], :]\n",
    "\n",
    "    xcenter = max_coordinate[0]\n",
    "    ycenter = max_coordinate[1]\n",
    "    w = max_coordinate[2]\n",
    "    h = max_coordinate[3]\n",
    "\n",
    "    xcenter = (index[1] + xcenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "    ycenter = (index[0] + ycenter) * (IMAGE_SIZE/float(CELL_SIZE))\n",
    "\n",
    "    w = w * IMAGE_SIZE\n",
    "    h = h * IMAGE_SIZE\n",
    "\n",
    "    xmin = xcenter - w/2.0\n",
    "    ymin = ycenter - h/2.0\n",
    "\n",
    "    xmax = xmin + w\n",
    "    ymax = ymin + h\n",
    "\n",
    "    return xmin, ymin, xmax, ymax, class_num, max_conf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img_files = open('./test_aug.txt')\n",
    "test_img_dir = './merged_image_aug/'\n",
    "test_images = []\n",
    "\n",
    "for line in test_img_files:\n",
    "    line = line.strip()\n",
    "    ss = line.split(' ')\n",
    "    test_images.append(os.path.join(test_img_dir,ss[0]))\n",
    "    \n",
    "test_dataset = tf.data.Dataset.from_tensor_slices(test_images)\n",
    "\n",
    "def load_img_data(image_name):\n",
    "    image_file = tf.io.read_file(image_name)\n",
    "    image = tf.image.decode_jpeg(image_file, channels=3)\n",
    "\n",
    "    h = tf.shape(image)[0]\n",
    "    w = tf.shape(image)[1]\n",
    "\n",
    "    image = tf.image.resize(image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = (image/255) * 2 - 1\n",
    "\n",
    "    return image_name, image, h, w\n",
    "\n",
    "test_dataset = test_dataset.map(load_img_data, num_parallel_calls = tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test_dataset.batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def prediction_step(img):\n",
    "    return YOLO(img, training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0xa8 in position 234: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m output_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./test_prediction_aug.txt\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img_name, test_img, img_h, img_w \u001b[38;5;129;01min\u001b[39;00m test_dataset:\n\u001b[0;32m      4\u001b[0m     batch_num \u001b[38;5;241m=\u001b[39m img_name\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(batch_num):\n",
      "File \u001b[1;32mc:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:810\u001b[0m, in \u001b[0;36mOwnedIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    808\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    809\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 810\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_internal\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    811\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m errors\u001b[38;5;241m.\u001b[39mOutOfRangeError:\n\u001b[0;32m    812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\tensorflow\\python\\data\\ops\\iterator_ops.py:773\u001b[0m, in \u001b[0;36mOwnedIterator._next_internal\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    770\u001b[0m \u001b[38;5;66;03m# TODO(b/77291417): This runs in sync mode as iterators use an error status\u001b[39;00m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# to communicate that there is no more data to iterate over.\u001b[39;00m\n\u001b[0;32m    772\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecution_mode(context\u001b[38;5;241m.\u001b[39mSYNC):\n\u001b[1;32m--> 773\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mgen_dataset_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator_get_next\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator_resource\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    775\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    776\u001b[0m \u001b[43m      \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_flat_output_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    778\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    779\u001b[0m     \u001b[38;5;66;03m# Fast path for the case `self._structure` is not a nested structure.\u001b[39;00m\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_element_spec\u001b[38;5;241m.\u001b[39m_from_compatible_tensor_list(ret)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Neo\\anaconda3\\envs\\neo\\lib\\site-packages\\tensorflow\\python\\ops\\gen_dataset_ops.py:3024\u001b[0m, in \u001b[0;36miterator_get_next\u001b[1;34m(iterator, output_types, output_shapes, name)\u001b[0m\n\u001b[0;32m   3022\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m   3023\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3024\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3025\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mIteratorGetNext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_types\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_types\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3026\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moutput_shapes\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3027\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m   3028\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0xa8 in position 234: invalid start byte"
     ]
    }
   ],
   "source": [
    "output_file = open('./test_prediction_aug.txt', 'w')\n",
    "\n",
    "for img_name, test_img, img_h, img_w in test_dataset:\n",
    "    batch_num = img_name.shape[0]\n",
    "    for i in range(batch_num):\n",
    "        xmin, ymin, xmax, ymax, class_num, conf = process_outputs(prediction_step(test_img[i:i+1]))\n",
    "        xmin, ymin, xmax, ymax = xmin*(img_w[i:i+1]/IMAGE_SIZE), ymin*(img_h[i:i+1]/IMAGE_SIZE), xmax*(img_w[i:i+1]/IMAGE_SIZE), ymax*(img_h[i:i+1]/IMAGE_SIZE)\n",
    "\n",
    "        #img filename, xmin, ymin, xmax, ymax, class, confidence\n",
    "        x=(xmin+xmax)/2\n",
    "        y=(ymin+ymax)/2\n",
    "        w=xmax-xmin\n",
    "        h=ymax-ymin\n",
    "        output_file.write(img_name[i:i+1].numpy()[0].decode('ascii')+\" %d %d %d %d %d %f\\n\" %(x, y, w, h, class_num, conf))\n",
    "\n",
    "output_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "neo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
